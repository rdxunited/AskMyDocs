{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1edd025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.llms import Ollama\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "916e3a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split into 13 chunks\n"
     ]
    }
   ],
   "source": [
    "loader = PyPDFLoader(\"attention.pdf\")\n",
    "pages = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "docs = text_splitter.split_documents(pages[:3]) ##limit to first 3 pages for testing\n",
    "\n",
    "print(f\"split into {len(docs)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34e12df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OllamaEmbeddings(model=\"llama2\")\n",
    "\n",
    "db = FAISS.from_documents(docs, embedding)\n",
    "\n",
    "db.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3bc10da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_16676\\627272458.py:1: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"llama2\")\n"
     ]
    }
   ],
   "source": [
    "llm = Ollama(model=\"llama2\")\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=db.as_retriever(),\n",
    "    chain_type=\"stuff\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25839632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: This document is about a new neural network architecture called the Transformer, which is designed specifically for sequence modeling tasks such as machine translation and constituency parsing. The Transformer relies entirely on attention mechanisms, rather than recurrence or convolutions, to draw global dependencies between input and output sequences. The document presents experimental results showing that the Transformer achieves superior quality compared to existing models while being more parallelizable and requiring less training time. Additionally, the Transformer is able to generalize well to other tasks by applying it successfully to English constituency parsing with both large and limited training data.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is this document about?\"\n",
    "result = qa.run(query)\n",
    "print(\"Answer:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d04868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4456044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d22bc38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
